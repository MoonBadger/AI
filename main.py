import matplotlib.pyplot as plt
import numpy as np

import data

# Масса бриллианта (один вектор признак - колонка)
x = data.x
# Стоимость бриллиантов (целевой вектор признак - колонка)
y = data.y

plt.figure(figsize=(10, 10)) # figsize - размер графика
plt.plot(x, y, 'ro') # выведем наши данные
plt.show()

# сгенерируем начальные значения параметров из нормального распределения
w = np.random.randn(1)  # вес (weight)
b = np.random.randn(1)  # сдвиг (bias)
# скорость обучения
lr = 0.01
# количество эпох (количество итераций обновления наших параметров)
n_epochs = 10000

# будем сохранять каждую итерацию ошибки
mse_list = []

# основной цикл обучения модели
for epoch in range(n_epochs):

    # делаем предсказание с текущими коэффициентами b и w и данными x
    y_pred = b + w * x

    # посчитаем функцию ошибки MSE
    mse = np.mean(((y - y_pred) ** 2))

    # сохраним ошибку
    mse_list.append(mse)

    # считаем градиенты при текущих параметрах (смотреть формулы полученных производных выше)
    b_grad = -2 * (y - y_pred).mean()  # для коэффициента b
    w_grad = -2 * ((y - y_pred) * x).mean()  # для коэффициента w

    # обновляем параметры, используя коэффициент скорости обучения
    b = b - lr * b_grad
    w = w - lr * w_grad

    if epoch % 20 == 0:
        print('MSE: эпоха ', epoch, ': ', mse)  # выведем ошибку каждую 20-ую итерацию обучения
print('Найденный параметр b: ', b)
print('Найденный параметр w: ', w)
y_pred = b+w*x # после нахождения параметров построим нашу линейную регрессию

plt.figure(figsize=(10, 10))
plt.plot(x, y, 'ro') # выведем наши данные
plt.plot(x, y_pred) # построим линейную регрессию
plt.show()

plt.figure(figsize=(10, 10))
plt.plot(range(n_epochs), mse_list, 'ro') # ось x - количество эпох(range(n_epochs)), ось y - наши ошибки(mse_list)
plt.title('Как менялась ошибка с каждой эпохой')
plt.show()